html$label('Dropdown'),
dccDropdown(
options = list(list(label = "New York City", value = "NYC"),
list(label = "Montreal", value = "MTL"),
list(label = "San Francisco", value = "SF")),
value = 'MTL'
),
html$label('Multi-Select Dropdown'),
dccDropdown(
options = list(list(label = "New York City", value = "NYC"),
list(label = "Montreal", value = "MTL"),
list(label = "San Francisco", value = "SF")),
value = list('MTL', 'SF'),
multi = TRUE
),
html$label('Radio Items'),
dccRadioItems(
options = list(list(label = "New York City", value = "NYC"),
list(label = "Montreal", value = "MTL"),
list(label = "San Francisco", value = "SF")),
value = 'MTL'
),
html$label('Checkboxes'),
dccChecklist(
options = list(list(label = "New York City", value = "NYC"),
list(label = "Montreal", value = "MTL"),
list(label = "San Francisco", value = "SF")),
value = list('MTL', 'SF')
),
html$label('Text Input'),
dccInput(value = 'MTL', type = 'text'),
html$label('Slider'),
dccSlider(
min = 0,
max = 9,
marks = c("", "Label 1", 2:5),
value = 5
),
style = list('columnCount' = 2)
)
)
app %>% run_app()
library(dash)
library(dashCoreComponents)
app <- dash_app()
app %>% set_layout(
html$h6("Change the value in the text box to see callbacks in action!"),
div(
"Input: ",
dccInput(id = 'my-input', value = 'initial value', type = 'text')
),
br(),
div(id = 'my-output')
)
app %>% add_callback(
output(id = 'my-output', property = 'children'),
input(id = 'my-input', property = 'value'),
function(input_value) {
sprintf("Output: \"%s\"", input_value)
}
)
app %>% run_app()
library(plotly)
data <- read.csv("https://www.dropbox.com/scl/fi/d3v41yp6x9cxlqvueoet3/membersClean.csv?rlkey=v9xfdgu6oyubjur9rlu6k9eow&dl=1")
fig <- plot_ly(data, x = ~age, color = ~sex, type = "box")
fig
x <- data$year
y <- data$season
fig <- plot_ly(data, x = ~x, color = ~y, type = "box")
fig
library(knitr)
library(corrplot)
library(FactoMineR)
library(factoextra)
knitr::opts_chunk$set(echo = FALSE,warning = FALSE)
station <- read.csv("~/yanis/cours/Master ssd/M1/Semestre 1/Analyse de données/stations.txt", sep="")
station_active <- station[,2:7]
acp <- PCA(station_active,graph=FALSE)
kable(head(station))
eig_val <- get_eigenvalue(acp)
valeur_propre <- eig_val[,1]
nbdim<-sum(valeur_propre) #egale au nombre de dimension de l'acp
#en prenant les 3 premieres composantes , on atteint 88%de la variance expliquée!
var <- get_pca_var(acp)
##coordoonées des variables pour un nuage d epoint
coor<-head(var$coord)
#qualité de représentation
cos2 <- head(var$cos2) # == head(var$coord*var$coord)
# contrib aux composantes principales
contrib <- head(var$contrib) #==var$cos2[,i]*100/sum(var$cos2[,i])
round(eig_val,0)
eig_val
eig_val[3]
eig_val[4]
eig_val[1,]
eig_val[13,]
eig_val[3,]
eig_val[3,][1]
eig_val[3,][3]
eig_val[3,3]
install.packages("C:/Users/Alex/Downloads/shinyWidgets_0.8.0.zip", repos = NULL, type = "win.binary")
install.packages("~/yanis/cours/Master ssd/M1/Semestre 1/package r/compar_0.0.0.9000.tar.gz", repos = NULL, type = "source")
require(compar)
AnalyseR::run_app()
AnalyseR::run_app()
AnalyseR::run_app()
data <- iris
AnalyseR::run_app()
data <- read.csv("https://www.dropbox.com/scl/fi/d3v41yp6x9cxlqvueoet3/membersClean.csv?rlkey=v9xfdgu6oyubjur9rlu6k9eow&dl=1")
AnalyseR::run_app()
require(AnalyseR)
run_app()
plot_qu
require(AnalyseR)
run_app()
run_app()
require(AnalyseR)
run_app()
require(cyclamedSampleR)
require(CyclamedSampleR)
setwd("C:/Users/Alex/Documents/yanis/cours/Master ssd/M1/Semestre_2/Apprentissage statistique/Projet/Projet")
require(dplyr)
require(tibble)
require(ggplot2)
require(dbscan)
knitr::opts_chunk$set(echo=FALSE,warning = FALSE,message = FALSE)
load("outlier-dataset.Rdata")
data <- tibble::as_tibble(X)
data <- mutate(data,cat=y)
ggplot(data,aes(x = V19,y = V20,color=cat))+geom_point()
best_acc <- 0
best_k <- 0
for(k in 2:15){
lof <- lof(X, minPts = k)
pred <- ifelse(lof>=2,"outlier","normal")
acc <- sum(pred == data$cat) / length(data$cat)
if(acc > best_acc){
best_acc <- acc
best_k <- i
}
}
for(k in 2:15){
lof <- lof(X, minPts = k)
pred <- ifelse(lof>=2,"outlier","normal")
acc <- sum(pred == data$cat) / length(data$cat)
if(acc > best_acc){
best_acc <- acc
best_k <- k
}
}
best_acc
best_k
lof <- lof(X,minPts = best_k)
lof <- lof(X,minPts = best_k)
lof
Accuracy(lof)
pred <- ifelse(lof>=2,"outlier","normal")
Metrics::accuracy(pred,data$cat)
accuracy(pred,data$cat)
require(Metrics)
accuracy(pred,data$cat)
sum(pred == data$cat)
length(data$cat)
sum(pred == data$cat)
score<- accuracy(pred,data$cat)
score
pred <- ifelse(lof>=2.2,"outlier","normal")
score<- accuracy(pred,data$cat)
score
score<- accuracy(pred,data$cat)
pred <- ifelse(lof>=2.5,"outlier","normal")
score<- accuracy(pred,data$cat)
score
pred <- ifelse(lof>=2.7,"outlier","normal")
score<- accuracy(pred,data$cat)
score
pred <- ifelse(lof>=2.9,"outlier","normal")
score<- accuracy(pred,data$cat)
score
pred <- ifelse(lof>=3,"outlier","normal")
score<- accuracy(pred,data$cat)
score
pred <- ifelse(lof>=4,"outlier","normal")
score<- accuracy(pred,data$cat)
score
pred <- ifelse(lof>=5,"outlier","normal")
score<- accuracy(pred,data$cat)
score
pred <- ifelse(lof>=8,"outlier","normal")
score<- accuracy(pred,data$cat)
score
pred <- ifelse(lof>=100,"outlier","normal")
score<- accuracy(pred,data$cat)
score
pred <- ifelse(lof>=10000,"outlier","normal")
score<- accuracy(pred,data$cat)
score
pred <- ifelse(lof== Inf,"outlier","normal")
score<- accuracy(pred,data$cat)
score
sum(pred == data$cat)
score<- accuracy(pred,data$cat)
score
best_acc <- 0
best_k <- 0
for(k in 2:15){
lof <- lof(X, minPts = k)
pred <- ifelse(lof==Inf,"outlier","normal")
acc <- sum(pred == data$cat) / length(data$cat)
if(acc > best_acc){
best_acc <- acc
best_k <- k
}
}
for(k in 2:15){
lof <- lof(X, minPts = k)
pred <- ifelse(lof==Inf,"outlier","normal")
acc <- sum(pred == data$cat) / length(data$cat)
if(acc > best_acc){
best_acc <- acc
best_k <- k
}
}
lof <- lof(X,minPts = best_k)
pred <- ifelse(lof== Inf,"outlier","normal")
score<- accuracy(pred,data$cat)
score
best_k
score
score<- accuracy(predicted,data$cat)
predicted <- ifelse(lof== Inf,"outlier","normal")
score<- accuracy(predicted,data$cat)
score
pred <- prediction(lof, data$cat)
pred <- prediction(lof,y)
require(ROCR)
pred <- prediction(lof,y)
# Créer un objet de performance ROC
perf <- performance(pred, "tpr", "fpr")
# Tracer la courbe ROC
plot(perf, main="Courbe ROC", col="blue", lwd=2)
# Calculer l'AUC
auc <- performance(pred, measure = "auc")
auc
auc <- auc@y.values[[1]]
auc
require(pROC)
pred
predict(lof,y)
roc(y,-lof)
auc
roc <- roc(y,-lof)
ggroc(roc)
ggroc(List(LOF=roc))
ggroc(list(LOF=roc))
ggroc(list(LOF=roc))+ annotate(geom="text",x = 0.9,y = 0.8)
ggroc(list(LOF=roc))+ annotate(geom="text",x = 0.9,y = 0.8,label = paste0("Auc=",auc(roc)))
ggroc(list(LOF=roc))+ annotate(geom="text",x = 0.1,y = 0.8,label = paste0("Auc=",auc(roc)))
ggroc(list(LOF=roc))+ annotate(geom="text",x = 0.1,y = 0.8,label = paste0("Auc=",round(auc(roc),2)))
ggroc(list(LOF=roc))+ annotate(geom="text",x = 0.1,y = 0.9,label = paste0("Auc=",round(auc(roc),2)))
ggroc(list(LOF=roc))+ annotate(geom="text",x = 0.1,y = 0.9,label = paste0("AUCc=",round(auc(roc),2)))
predicted <- ifelse(lof== Inf,"outlier","normal")
score<- accuracy(predicted,data$cat)
score
predicted <- ifelse(lof== 2,"outlier","normal")
score<- accuracy(predicted,data$cat)
score
lof
predicted <- ifelse(lof== 2,"outlier","normal")
score<- accuracy(predicted,data$cat)
score
predicted <- ifelse(lof>= 2,"outlier","normal")
score<- accuracy(predicted,data$cat)
score
# on créer un objet roc
roc <- roc(y,-lof)
# trace les courbes roc
ggroc(list(LOF=roc))+ annotate(geom="text",x = 0.1,y = 0.9,label = paste0("AUC=",round(auc(roc),2)))
# on créer un objet roc
roc <- roc(y,-lof)
# trace les courbes roc
ggroc(list(LOF=roc))+ annotate(geom="text",x = 0.1,y = 0.9,label = paste0("AUC=",round(auc(roc),2)))
predicted <- ifelse(lof== 2,"outlier","normal")
score<- accuracy(predicted,data$cat)
score
sum(lof==2)
sum(lof>2)
sum(lof>=2)
sum(lof==Inf)
lof
sum(lof>=Inf)
sum(lof>=100000)
sum(lof>=10)
sum(y=="outlier")
sum(lof>=3)
sum(lof>=2.2)
sum(lof>=2.3)
sum(lof>=2.4)
sum(lof>=2.33
)
sum(lof>=2.35)
sum(lof>=2.36)
predicted <- ifelse(lof>= 2.36,"outlier","normal")
score<- accuracy(predicted,data$cat)
score
# on créer un objet roc
roc <- roc(y,-lof)
# trace les courbes roc
ggroc(list(LOF=roc))+ annotate(geom="text",x = 0.1,y = 0.9,label = paste0("AUC=",round(auc(roc),2)))
predicted <- ifelse(lof>= 2,"outlier","normal")
score
# trace les courbes roc
ggroc(list(LOF=roc))+ annotate(geom="text",x = 0.5,y = 0.9,label = paste0("AUC=",round(auc(roc),2),"accuracy=",round(score,2)))
# trace les courbes roc
ggroc(list(LOF=roc))+ annotate(geom="text",x = 0.5,y = 0.9,label = paste0("AUC=",round(auc(roc),2),",ACCURACY=",round(score,2)))
require(isotree)
isotree
require(isotree)
install.packages("isotree")
require(isotree)
model_forest <- isolation.forest(X)
model_forest
pred <- predict(model_forest,X)
pred
max(pred)
min(pred)
summary(pred)
boxplot(pred)
sum(pred>0.5)
sum(pred>0.4)
sum(pred>0.45)
predicted <- ifelse(pred>0.45,"outlier","normal")
score_iso <- accuracy(predicted,y)
score_iso
predicted <- ifelse(pred>0.5,"outlier","normal")
score_iso <- accuracy(predicted,y)
score_iso
predicted <- ifelse(pred>0.35,"outlier","normal")
score_iso <- accuracy(predicted,y)
score_iso
predicted <- ifelse(pred>0.45,"outlier","normal")
score_iso <- accuracy(predicted,y)
score_iso
roc2 <- roc(y, -pred)
model_forest <- isolation.forest(X)
model_forest <- isolation.forest(X)
pred <- predict(model_forest,X)
predicted <- ifelse(pred>0.45,"outlier","normal")
predicted <- ifelse(pred>0.45,"outlier","normal")
score_iso <- accuracy(predicted,y)
# on créer un objet roc
roc <- roc(y,-lof)
roc2 <- roc(y, -pred)
# trace les courbes roc
ggroc(list(LOF=roc,IsolationForest=roc2))+ annotate(geom="text",x = 0.5,y = 0.9,label = paste0("AUC=",round(auc(roc),2),",ACCURACY=",round(score,2)))
# trace les courbes roc
ggroc(list(LOF=roc,IsolationForest=roc2))+ annotate(geom="text",x = 0.8,y = 0.9,label = paste0("LOF: AUC=",round(auc(roc),2),",ACCURACY=",round(score,2)))
# trace les courbes roc
ggroc(list(LOF=roc,IsolationForest=roc2))+ annotate(geom="text",x = 0.6,y = 0.9,label = paste0("LOF: AUC=",round(auc(roc),2),",ACCURACY=",round(score,2)))
# trace les courbes roc
ggroc(list(LOF=roc,IsolationForest=roc2))+ annotate(geom="text",x = 0.7,y = 0.9,label = paste0("LOF: AUC=",round(auc(roc),2),",ACCURACY=",round(score,2)))
# trace les courbes roc
ggroc(list(LOF=roc,IsolationForest=roc2))+
annotate(geom="text",x = 0.7,y = 0.9,label = paste0("LOF: AUC=",round(auc(roc),2),",ACCURACY=",round(score,2)))+
annotate(geom="text",x = 0.7,y = 0.9,label = paste0("Iso: AUC=",round(auc(roc2),2),",ACCURACY=",round(score_iso,2)))
# trace les courbes roc
ggroc(list(LOF=roc,IsolationForest=roc2))+
annotate(geom="text",x = 0.7,y = 0.9,label = paste0("LOF: AUC=",round(auc(roc),2),",ACCURACY=",round(score,2)))+
annotate(geom="text",x = 0.7,y = 0.8,label = paste0("Iso: AUC=",round(auc(roc2),2),",ACCURACY=",round(score_iso,2)))
# trace les courbes roc
ggroc(list(LOF=roc,IsolationForest=roc2))+
annotate(geom="text",x = 0.7,y = 0.9,label = paste0("LOF: AUC=",round(auc(roc),2),",ACCURACY=",round(score,2)))+
annotate(geom="text",x = 0.7,y = 0.8,label = paste0("ISO: AUC=",round(auc(roc2),2),",ACCURACY=",round(score_iso,2)))
scale(X)
X_norm <- scale(X)
best_acc <- 0
best_k <- 0
for(k in 2:15){
lof <- lof(X, minPts = k)
pred <- ifelse(lof==Inf,"outlier","normal")
acc <- sum(pred == data$cat) / length(data$cat)
if(acc > best_acc){
best_acc <- acc
best_k <- k
}
}
lof <- lof(X,minPts = best_k)
predicted <- ifelse(lof>= 2,"outlier","normal")
score<- accuracy(predicted,data$cat)
score
require(FactoMineR)
require(FactoMineR)
require(factoextra)
ACP <- PCA(X,scale.unit = TRUE)
ACP <- PCA(X,scale.unit = TRUE,graph = FALSE)
get_eig(ACP)
ACP <- PCA(X,graph = FALSE)
get_eig(ACP)
,scale.unit = TRUE
,scale.unit = TRUE
ACP <- PCA(X,scale.unit = TRUE,graph = FALSE)
get_eig(ACP)
ACP <- PCA(X_normgraph = FALSE)
ACP <- PCA(X_norm,graph = FALSE)
get_eig(ACP)
ACP <- PCA(scale(X),graph = FALSE)
get_eig(ACP)
ACP$eig
ACP$var
ACP$ind
get_eig(ACP)
get_eig(ACP)[,3]
get_eig(ACP)[,3]>80
which.min(get_eig(ACP)[,3]>80)
which.max(get_eig(ACP)[,3]>80)
which.max(get_eig(ACP)[,3]<80)
which.min(get_eig(ACP)[,3]<80)
name(which.min(get_eig(ACP)[,3]<80))
rowname(which.min(get_eig(ACP)[,3]<80))
which.min(get_eig(ACP)[,3]<80)
which.min(get_eig(ACP)[,3]<60)
dim <- 10
X_pca <- ACP[,1:dim]$ind$coord
ACP[,1:dim]
X_pca <- ACP[1:dim]$ind$coord
X_pca
head(X_pca)
dim
1:dim
ACP
ACP[1]
ACP$ind$coord[,1:10]
ACP$ind$coord
get_eig(ACP) # on garde 10 dimensions
ACP$ind$coord[11]
ACP$ind$coord[,11]
ACP$ind$coord[1]
X_pca <- PCA(scale(X),ncp = 10,graph = FALSE)
head(X_pca)
get_eig(X_pca)
X_pca <- PCA(scale(X),ncp = 10,graph = FALSE)
X_pca <- PCA(scale(X),ncp = 10,graph = FALSE)$ind$coord
head(X_pca)
best_acc <- 0
best_k <- 0
for(k in 2:15){
lof <- lof(X_pca, minPts = k)
pred <- ifelse(lof==Inf,"outlier","normal")
acc <- sum(pred == data$cat) / length(data$cat)
if(acc > best_acc){
best_acc <- acc
best_k <- k
}
}
lof <- lof(X_pca,minPts = best_k)
predicted <- ifelse(lof>= 2,"outlier","normal")
score<- accuracy(predicted,data$cat)
score
model_forest <- isolation.forest(X_pca)
pred <- predict(model_forest,X)
pred <- predict(model_forest,X)
predicted <- ifelse(pred>0.45,"outlier","normal")
predicted <- ifelse(pred>0.45,"outlier","normal")
score_iso <- accuracy(predicted,y)
# on créer un objet roc
roc <- roc(y,-lof)
roc2 <- roc(y, -pred)
# trace les courbes roc
ggroc(list(LOF=roc,IsolationForest=roc2))+
annotate(geom="text",x = 0.7,y = 0.9,label = paste0("LOF: AUC=",round(auc(roc),2),",ACCURACY=",round(score,2)))+
annotate(geom="text",x = 0.7,y = 0.8,label = paste0("ISO: AUC=",round(auc(roc2),2),",ACCURACY=",round(score_iso,2)))
# trace les courbes roc
ggroc(list(LOF=roc,IsolationForest=roc2))+
annotate(geom="text",x = 0.7,y = 0.9,label = paste0("LOF: AUC=",round(auc(roc),2),",ACCURACY=",round(score,2)))+
annotate(geom="text",x = 0.7,y = 0.8,label = paste0("ISO: AUC=",round(auc(roc2),2),",ACCURACY=",round(score_iso,2)))+ ggtitle("Courbes ROC des modèles sur ACP normalisé")
# trace les courbes roc
ggroc(list(LOF=roc,IsolationForest=roc2))+
annotate(geom="text",x = 0.7,y = 0.9,label = paste0("LOF: AUC=",round(auc(roc),2),",ACCURACY=",round(score,2)))+
annotate(geom="text",x = 0.7,y = 0.8,label = paste0("ISO: AUC=",round(auc(roc2),2),",ACCURACY=",round(score_iso,2)))+ ggtitle("Courbe ROC des modèles")
best_acc <- 0
for(n in c(10,25,50,75,100,150,200)){
iso <- isolation.forest(X_pca,ntrees = n)
pred <- predict(model_forest,X)
predicted <- ifelse(pred>0.45,"outlier","normal")
score_iso <- accuracy(predicted,y)
if(score_iso > best_acc){
best_acc <- score_iso
best_ntrees <- n
}
}
model_forest <- isolation.forest(X_pca,ntrees = best_ntrees)
pred <- predict(model_forest,X)
predicted <- ifelse(pred>0.45,"outlier","normal")
score_iso <- accuracy(predicted,y)
# on créer un objet roc
roc <- roc(y,-lof)
roc2 <- roc(y, -pred)
# trace les courbes roc
ggroc(list(LOF=roc,IsolationForest=roc2))+
annotate(geom="text",x = 0.7,y = 0.9,label = paste0("LOF: AUC=",round(auc(roc),2),",ACCURACY=",round(score,2)))+
annotate(geom="text",x = 0.7,y = 0.8,label = paste0("ISO: AUC=",round(auc(roc2),2),",ACCURACY=",round(score_iso,2)))+ ggtitle("Courbes ROC des modèles sur ACP normalisé")
250/length(X)
0.45
length(X)
nrow(data)
250/nrow(data)
pred
summary(pred)
pred <- predict(model_forest,X)
quantile(pred, probs = 0.95)
predicted <- ifelse(pred>quantile(pred, probs = 0.95),"outlier","normal")
score_iso <- accuracy(predicted,y)
