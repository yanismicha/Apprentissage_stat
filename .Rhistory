library(dash)
library(dashCoreComponents)
library(dashHtmlComponents)
library(dashTable)
library(plotly)
# Create a Dash app
app <- dash_app()
# Set the layout of the app
app %>% set_layout(
h1('Hello Dash'),
div("Dash: A web application framework for your data."),
dccGraph(
figure = list(
data = list(
list(
x = list(1, 2, 3),
y = list(4, 1, 2),
type = 'bar',
name = 'SF'
),
list(
x = list(1, 2, 3),
y = list(2, 4, 5),
type = 'bar',
name = 'Montr\U{00E9}al'
)
),
layout = list(title = 'Dash Data Visualization')
)
)
)
# Run the app
app %>% run_app()
# Run the app
app %>% run_app()
# Charger les bibliothèques Dash
library(dash)
library(dashCoreComponents)
library(dashHtmlComponents)
library(dashTable)
library(plotly)
df <- read.csv(
file = "https://raw.githubusercontent.com/plotly/datasets/master/gapminderDataFiveYear.csv",
stringsAsFactor = FALSE,
check.names = FALSE
)
continents <- unique(df$continent)
data_gdp_life_exp_2007 <- lapply(
continents,
function(cont) {
list(
x = df$gdpPercap[df$continent == cont],
y = df$lifeExp[df$continent == cont],
opacity = 0.7,
text = df$country[df$continent == cont],
mode = 'markers',
name = cont,
marker = list(size = 15, line = list(width = 0.5, color = 'white'))
)
}
)
app <- dash_app()
app %>% set_layout(
dccGraph(
id = 'life-exp-vs-gdp',
figure = list(
data =  data_gdp_life_exp_2007,
layout = list(
xaxis = list('type' = 'log', 'title' = 'GDP Per Capita'),
yaxis = list('title' = 'Life Expectancy'),
margin = list('l' = 40, 'b' = 40, 't' = 10, 'r' = 10),
legend = list('x' = 0, 'y' = 1),
hovermode = 'closest'
)
)
)
)
app %>% run_app()
# Run the app
app %>% run_app()
library(dash)
library(dashCoreComponents)
markdown_text <- "
### Dash and Markdown
Dash apps can be written in Markdown.
Dash uses the [CommonMark](http://commonmark.org/)
specification of Markdown.
Check out their [60 Second Markdown Tutorial](http://commonmark.org/help/)
if this is your first introduction to Markdown!
"
dash_app() %>%
set_layout(dccMarkdown(markdown_text)) %>%
run_app()
library(dash)
library(dashCoreComponents)
app <- dash_app()
app %>% set_layout(
div(
html$label('Dropdown'),
dccDropdown(
options = list(list(label = "New York City", value = "NYC"),
list(label = "Montreal", value = "MTL"),
list(label = "San Francisco", value = "SF")),
value = 'MTL'
),
html$label('Multi-Select Dropdown'),
dccDropdown(
options = list(list(label = "New York City", value = "NYC"),
list(label = "Montreal", value = "MTL"),
list(label = "San Francisco", value = "SF")),
value = list('MTL', 'SF'),
multi = TRUE
),
html$label('Radio Items'),
dccRadioItems(
options = list(list(label = "New York City", value = "NYC"),
list(label = "Montreal", value = "MTL"),
list(label = "San Francisco", value = "SF")),
value = 'MTL'
),
html$label('Checkboxes'),
dccChecklist(
options = list(list(label = "New York City", value = "NYC"),
list(label = "Montreal", value = "MTL"),
list(label = "San Francisco", value = "SF")),
value = list('MTL', 'SF')
),
html$label('Text Input'),
dccInput(value = 'MTL', type = 'text'),
html$label('Slider'),
dccSlider(
min = 0,
max = 9,
marks = c("", "Label 1", 2:5),
value = 5
),
style = list('columnCount' = 2)
)
)
app %>% run_app()
library(dash)
library(dashCoreComponents)
app <- dash_app()
app %>% set_layout(
html$h6("Change the value in the text box to see callbacks in action!"),
div(
"Input: ",
dccInput(id = 'my-input', value = 'initial value', type = 'text')
),
br(),
div(id = 'my-output')
)
app %>% add_callback(
output(id = 'my-output', property = 'children'),
input(id = 'my-input', property = 'value'),
function(input_value) {
sprintf("Output: \"%s\"", input_value)
}
)
app %>% run_app()
library(plotly)
data <- read.csv("https://www.dropbox.com/scl/fi/d3v41yp6x9cxlqvueoet3/membersClean.csv?rlkey=v9xfdgu6oyubjur9rlu6k9eow&dl=1")
fig <- plot_ly(data, x = ~age, color = ~sex, type = "box")
fig
x <- data$year
y <- data$season
fig <- plot_ly(data, x = ~x, color = ~y, type = "box")
fig
library(knitr)
library(corrplot)
library(FactoMineR)
library(factoextra)
knitr::opts_chunk$set(echo = FALSE,warning = FALSE)
station <- read.csv("~/yanis/cours/Master ssd/M1/Semestre 1/Analyse de données/stations.txt", sep="")
station_active <- station[,2:7]
acp <- PCA(station_active,graph=FALSE)
kable(head(station))
eig_val <- get_eigenvalue(acp)
valeur_propre <- eig_val[,1]
nbdim<-sum(valeur_propre) #egale au nombre de dimension de l'acp
#en prenant les 3 premieres composantes , on atteint 88%de la variance expliquée!
var <- get_pca_var(acp)
##coordoonées des variables pour un nuage d epoint
coor<-head(var$coord)
#qualité de représentation
cos2 <- head(var$cos2) # == head(var$coord*var$coord)
# contrib aux composantes principales
contrib <- head(var$contrib) #==var$cos2[,i]*100/sum(var$cos2[,i])
round(eig_val,0)
eig_val
eig_val[3]
eig_val[4]
eig_val[1,]
eig_val[13,]
eig_val[3,]
eig_val[3,][1]
eig_val[3,][3]
eig_val[3,3]
install.packages("C:/Users/Alex/Downloads/shinyWidgets_0.8.0.zip", repos = NULL, type = "win.binary")
install.packages("~/yanis/cours/Master ssd/M1/Semestre 1/package r/compar_0.0.0.9000.tar.gz", repos = NULL, type = "source")
require(compar)
AnalyseR::run_app()
AnalyseR::run_app()
AnalyseR::run_app()
data <- iris
AnalyseR::run_app()
data <- read.csv("https://www.dropbox.com/scl/fi/d3v41yp6x9cxlqvueoet3/membersClean.csv?rlkey=v9xfdgu6oyubjur9rlu6k9eow&dl=1")
AnalyseR::run_app()
require(AnalyseR)
run_app()
plot_qu
require(AnalyseR)
run_app()
run_app()
require(AnalyseR)
run_app()
require(cyclamedSampleR)
require(CyclamedSampleR)
shiny::runApp('test')
runApp('test')
runApp('test')
runApp('test')
library(shinydashboardPlus)
runApp('test')
runApp('test')
runApp('test')
runApp('test')
runApp('test')
runApp('test')
runApp('test')
runApp('test')
require()
runApp('test')
runApp('test')
runApp('test')
runApp('test')
runApp('test')
runApp('test')
runApp('test')
getwd()
runApp('test')
setwd("C:/Users/Alex/Documents/test")
runApp('test')
setwd("C:/Users/Alex/Documents")
setwd("C:/Users/Alex/Documents")
runApp('test')
runApp('test')
runApp('test')
runApp('test')
runApp('test')
runApp('test')
runApp('test')
runApp('test')
runApp('test')
runApp('test')
getwd()
runApp('test')
runApp('test')
runApp('test')
runApp('test')
runApp('test')
shiny::runApp('test')
source("~/test/app.R")
runApp('test')
runApp('test2')
#devtools::install_github("Appsilon/shiny.semantic")
library(shiny.semantic)
#devtools::install_github("Appsilon/shiny.semantic")
library(shiny.semantic)
runApp('test2')
runApp('test2')
setwd("C:/Users/Alex/Documents/yanis/cours/Master ssd/M1/Semestre_2/Apprentissage statistique/TP")
load("regression-dataset.Rdata")
require(ggplot2)
require(MASS)
require(mclust)
require(FactoMineR)
require(factoextra)
plot(lm(y~ x))
plot(x,y)
abline(lm(y~x),col= "red")
x.grid = seq(min(x),max(x),by = 0.01)
deg.list=c(1:5,8,10,15,20)
MSE=c()
for(d in deg.list){
fit = lm( y ~ poly(x,d,raw = TRUE))
mse =mean(( y - fit$fitted.values)^2)
MSE=c(MSE,mse)
cat("*** degree",d,": MSE on training data=",mse,"***\n")
}
#fx.grid = predict(fit3,newdata = data.frame(("x"= x.test)))
plot(deg.list,MSE,type = "b",xlab = "polynomial degree",ylab = "MSE", main = "MSE vs Degree of polynomials")
poly(1:100,1)
poly(1:10,degree = 1,raw = TRUE)
poly(1:10,degree = 2,raw = TRUE)
poly(1:10,degree = 3,raw = TRUE)
(1:10)^3
x.grid = seq(min(x),max(x),by = 0.01)
deg.list=c(1:5,8,10,15,20)
MSE=c()
for(d in deg.list){
fit = lm( y ~ x^d)
mse =mean(( y - fit$fitted.values)^2)
MSE=c(MSE,mse)
cat("*** degree",d,": MSE on training data=",mse,"***\n")
}
x.grid = seq(min(x),max(x),by = 0.01)
deg.list=c(1:5,8,10,15,20)
MSE=c()
for(d in deg.list){
fit = lm( y ~ (x^d))
mse =mean(( y - fit$fitted.values)^2)
MSE=c(MSE,mse)
cat("*** degree",d,": MSE on training data=",mse,"***\n")
}
fit = lm( y ~ (x^d))
(x^d)
poly(x,d,raw=T)
lm( y ~ (x^d))
x^d
lm( y ~ (x^d))
fit = lm( y ~ poly(x,d,T))
fit = lm( y ~ poly(x,d,raw = TRUE))
poly(x,d,raw = TRUE)
xd = x^d
fit = lm( y ~ xd)
x.grid = seq(min(x),max(x),by = 0.01)
deg.list=c(1:5,8,10,15,20)
MSE=c()
for(d in deg.list){
xd = x^d
fit = lm( y ~ xd)
mse =mean(( y - fit$fitted.values)^2)
MSE=c(MSE,mse)
cat("*** degree",d,": MSE on training data=",mse,"***\n")
}
#fx.grid = predict(fit3,newdata = data.frame(("x"= x.test)))
plot(deg.list,MSE,type = "b",xlab = "polynomial degree",ylab = "MSE", main = "MSE vs Degree of polynomials")
x.grid = seq(min(x),max(x),by = 0.01)
deg.list=c(1:5,8,10,15,20)
MSE=c()
for(d in deg.list){
xd = x^d
fit = lm( y ~ poly(x,d,raw = T))
mse =mean(( y - fit$fitted.values)^2)
MSE=c(MSE,mse)
cat("*** degree",d,": MSE on training data=",mse,"***\n")
}
#fx.grid = predict(fit3,newdata = data.frame(("x"= x.test)))
plot(deg.list,MSE,type = "b",xlab = "polynomial degree",ylab = "MSE", main = "MSE vs Degree of polynomials")
MSE.test=c()
for(d in deg.list){
fit = lm( y ~ poly(x,d,raw = TRUE))
preds = predict(fit, newdata = data.frame("x"=x.test))
mse =mean(( y.test - preds)^2)
MSE.test=c(MSE.test,mse)
cat("*** degree",d,": MSE on test data=",mse,"***\n")
}
plot(deg.list,ylim= range(c(MSE,MSE.test)),MSE,type = "b",xlab = "polynomial degree",ylab = "MSE",main="MSE vs degree")
coord <- data.frame(x = ACP$ind$coord[ind.grid,1],y =ACP$ind$coord[ind.grid,2])
ACP <- PCA(X,graph = FALSE)
X <- apply(I,3,as.vector)
load("digits-3.Rdata")
ind.grid
cols = gray(seq(1,0,length.out=256))
par(mfrow = c(n,n))
X <- apply(I,3,as.vector)
X <- t(X)
ACP <- PCA(X,graph = FALSE)
fviz_pca_biplot(ACP)
eig <- get_eigenvalue(ACP)
I1 <- matrix(ACP$var$coord[,1],nrow = 16)
I2 <- matrix(ACP$var$coord[,2],nrow = 16)
par(mfrow = c(1,2))
image(I1, col = cols, main = "first principal component", axes = F)
box()
image(I2, col = cols, main = "second principal component", axes = F)
box()
par(mfrow = c(5,5))
par(mar = c(1,1,1,1))
for(i in 1:dim(ind.grid)[1]){
for(j in 1:dim(ind.grid)[2]){
image(I[,,ind.grid[i,j]],col = cols)
box()
}
}
coord <- data.frame(x = ACP$ind$coord[ind.grid,1],y =ACP$ind$coord[ind.grid,2])
fviz_pca_ind(ACP,geom = c("point"))+ geom_point(data = coord,aes(x = x, y = y,color= "darkred"))
load("spectra.Rdata")
plot(X[1,],type="l", ylim = c(min(X),max(X)),col=y[1])
for(i in 2:nrow(X)){
lines(X[i,],col=y[i])
}
data <- data.frame(X = t(X),Y=1:100)
fig=ggplot(data,aes(y= X.1,x=Y))+geom_line(color=y[1])
fig
for(i in 2:215){
fig=fig+geom_line(aes(y=!!sym(paste0("X.",i)),x=Y),color=y[i])
}
fig
d <- dist(X)
CMDS = cmdscale(d, k = 2)
plot(CMDS, col = y)
ggplot(data.frame(CMDS,cat=y),aes(x=X1,y=X2,color=factor(cat)))+geom_point()
d <- as.dist(1-cor(t(X),method = "pearson"))
CMDS <- cmdscale(d)
plot(CMDS, col = y)
ggplot(data.frame(CMDS,cat=y),aes(x=X1,y=X2,color=factor(cat)))+geom_point()
d <- as.matrix(d)
ind1 = which(y ==1)
ind2 = which(y==2)
d1 <- as.matrix(dist(X))
boxplot(list("1-1"= d1[ind1,ind1],"2-2" = d1[ind2,ind2],"1-2" = d1[ind1,ind2]), outline = F,main = "distance euclidienne")
data.frame(d1)
boxplot(list("1-1"= d[ind1,ind1],"2-2" = d[ind2,ind2],"1-2" = d[ind1,ind2]), outline = F,main = "dissmilarité correlation")
par(mfrow=c(1,2))
plot(cmdscale(d1), col = y)
acp <- PCA(X,graph =  F)
fviz_pca_ind(acp,geom = "point",col.ind = factor(y))
load("exo-4.Rdata")
head(X)
source("utils.R")
# fit model
svm.model = svm(X, type='one-classification', nu=0.1, kernel="radial")
library(FactoMineR)
library(factoextra)
library(e1071)
require(ggplot2)
require(mclust)
source("utils.R")
# fit model
svm.model = svm(X, type='one-classification', nu=0.1, kernel="radial")
# make predictions
y.pred = predict(svm.model, X)
# show outliers
plot(X[,1], X[,2], col = factor(y.pred), xlab = "x1", ylab = "x2")
# show decision boundary
svm_pred = function(x){
return( predict(svm.model, x))
}
plot_with_contours(X, svm_pred, y = factor(y.pred))
require(NMF)
load("nci_small.Rdata")
require(NMF)
load("nci_small.Rdata")
install.packages("biobase")
install.packages("Biobase")
require(NMF)
load("nci_small.Rdata")
load("digits.Rdata")
clust = hclust(dist(X),method = "ward.D2")
km.clust <- kmeans(X, 10)$cluster
fviz_dend(clust,repel = TRUE,k=10,cex = 0.5,
color_labels_by_k = FALSE, rect = TRUE,label_cols =  km.clust[clust$order])+ labs(title =  "Clust avec ward.D2")
cut <- cutree(clust,k=10)
table(cut,y)
require(pheatmap)
pheatmap(table(cut,y))
clust = hclust(dist(X.large))
require(plotly)
names(cutree(clust,k=10)[1])
data = data.frame(X= names(cutree(clust,k=10)),group=cutree(clust,k=10),valeur=y.large)
barplot = ggplot(data,aes(x = group,fill = factor(y.large)))+geom_bar()
barplot
barplot = ggplot(data,aes(x = group,fill = factor(y.large)))+geom_bar()
barplot
require(ROCR)
require(ggplot2)
library(pROC)
load("DataTp4/tp-4_exo-1.Rdata")
for(i in 1:3){
data[[paste0("cat",i)]] <- ifelse(data[[paste0("score",i)]]>=0,1,0)
}
TP <- nrow(data[data$label==1 & data$cat1==1,])
FP <- nrow(data[data$label==0 & data$cat1==1,])
TN <- nrow(data[data$label==0 & data$cat1==0,])
FN <-  nrow(data[data$label==1 & data$cat1==0,])
cont1 <- table(data$label,data$cat1)
cont2 <- table(data$label,data$cat2)
cont3 <- table(data$label,data$cat3)
sensi1 <- cont1[2,2]/(cont1[2,2]+cont1[2,1])
sensi2 <- cont2[2,2]/(cont2[2,2]+cont2[2,1])
sensi3 <- cont3[2,2]/(cont3[2,2]+cont3[2,1])
speci1 <- cont1[1,1]/(cont1[1,1]+cont1[1,2])
speci2 <- cont2[1,1]/(cont2[1,1]+cont2[1,2])
speci3 <- cont3[1,1]/(cont3[1,1]+cont3[1,2])
for(i in 1:3){
cat("*** Sensibilité du",i,ifelse(i==1,"er","eme"),"classifieur:", get(paste0("sensi",i))*100,"%","***\n")
cat("*** Spécificité du",i,ifelse(i==1,"er","eme"),"classifieur:",get(paste0("speci",i))*100,"%","***\n")
}
Metrics::accuracy(data$label,data$cat1)
for(i in 1:3){
cat("*** Sensibilité du",i,ifelse(i==1,"er","eme"),"classifieur:", get(paste0("sensi",i))*100,"%","***\n")
cat("*** Spécificité du",i,ifelse(i==1,"er","eme"),"classifieur:",get(paste0("speci",i))*100,"%","***\n")
}
Metrics::accuracy(data$label,data$cat1)
caret::confusionMatrix(data$label,data$cat1)
data$label
data$cat1
data$cat1
data$labe
as.factor(data$label)
caret::confusionMatrix(as.factor(data$label),as.factor(data$cat1))
for(i in 1:3){
cat("*** Sensibilité du",i,ifelse(i==1,"er","eme"),"classifieur:", get(paste0("sensi",i))*100,"%","***\n")
cat("*** Spécificité du",i,ifelse(i==1,"er","eme"),"classifieur:",get(paste0("speci",i))*100,"%","***\n")
}
for(i in 1:3){
cat("*** Sensibilité du",i,ifelse(i==1,"er","eme"),"classifieur:", get(paste0("sensi",i))*100,"%","***\n")
cat("*** Spécificité du",i,ifelse(i==1,"er","eme"),"classifieur:",get(paste0("speci",i))*100,"%","***\n")
}
caret::confusionMatrix(as.factor(data$label),as.factor(data$cat1))
